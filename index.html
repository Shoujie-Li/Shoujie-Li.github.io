<!DOCTYPE HTML>
<html>
  <head>
    <!-- Google analytics tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-STGLQW4BJX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-STGLQW4BJX');
    </script>

    <!-- Title -->
    <title>Shoujie Li</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=1000">

    <!-- Isotope JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
    <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

    <!-- Custom Style -->
    <link rel="stylesheet" href="style.css">

    <!-- Google Font -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap" rel="stylesheet">
    <style>
      @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');
    </style>
  </head>

  <body id="body">
    <div id="main">
      <div id="intro">
        <div id="intro-text">
          <h1>Shoujie Li (李寿杰) </h1>
          <h2> <a href="#" id="toggleLink">How to pronounce?</a> </h2>
          
          <audio id="myAudioPlayer" style="display:none;" controls>
            <source src="media/pronounce.mp3" type="audio/mpeg">
            Your browser does not support the audio element.
          </audio>
          <p>
            Currently, I am a Research Fellow at Nanyang Technological University. 
            In June 2025, I obtained a doctoral degree in Data Science and Information Technology from Tsinghua University and was honored as  <b> the Outstanding Doctoral Graduate </b> of Tsinghua University and received <b> the Outstanding Doctoral Dissertation Award </b> from Tsinghua University</a>.
            <br>
            <br>
            I am very fortunate to be advised by  <a href="https://ssr-group.net/">Prof. Wenbo Ding</a>  of the SSR group from Tsinghua University. Previously, I pursued a master's degree in Artificial Intelligence at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> in 2023,
            advised by <a href="https://www.sigs.tsinghua.edu.cn/wxq_en/main.htm">Prof. Xueqian Wang</a>.
            <br>
            <br>
            I received <b>the Outstanding Mechanisms and Design Paper Finalists</b>  in ICRA 2022 ,  <b> the Best Application Paper Finalists</b> in IROS 2023, and 2023 Shenzhen Excellent Science and Technology Paper. 
            I won <b> first place in the Robotic Grasping of Manipulation Competition-Picking in Clutter</b>  in ICRA 2024. 
            During my PhD studies at Tsinghua, I was awarded the National Scholarship for Doctoral Students, the Future Scholars Scholarship, and the Future Leaders Excellence Scholarship.

            <br>
            <br>
            My research focuses on robotic perception, grippers designed, and embodied AI, with applications mainly on robotic manipulation.
        
            <br>
            <br>
            Feel free to reach out for collaboration and discussion of research ideas.
            <br>
            <br>
            Email: shoujie.li@ntu.edu.sg
            <br>
            <br>
            <!-- <a href="https://github.com/dengyh16code">Github</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://scholar.google.com/citations?user=KdN7CjEAAAAJ&hl=en">Google Scholar</a>&nbsp;&nbsp;&nbsp;&nbsp;
            <a href="https://www.linkedin.com/in/yuhong-deng">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
            <!-- <a href="https://dengyh16code.github.io/CV_YuhongDeng.pdf">Resume</a> (usually out-dated)&nbsp;&nbsp;&nbsp;&nbsp; -->
            <!-- <a href="https://bigfive-test.com/result/656b61265b905d00082551f2">Personality</a> -->
          </p>
        </div>
        <div id="intro-image">
          <img src="media/images/main_page/1.jpg">
        </div>
      </div>

      <div id="filters" class="button-group">
        <button class="button" data-filter=".talk">News</button>
        <!-- <button class="button" data-filter="*">Show All</button> -->
        <button class="button is-checked" data-filter=".publication">Research</button>
        <button class="button" data-filter=".highlight">Honors</button>
        <button class="button" data-filter=".misc">Services</button>
      </div>

      <div class="grid">





        



    
        <div class="list-item publication" data-category="publication">
          <h2 class="subsection-title publication">Representative works</h2>
        </div>
      




        <!-- Publications -->



        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\nats2026\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>Biomimetic multimodal tactile sensing enables human-like robotic perception</h3>
            <p>
              <i><b>Shoujie Li*</b>, Tong Wu*, Jianle Xu*, Yan Huang, Zongwen Zhang, Hongfa Zhao, Qinghao Xu, Zihan Wang, Linqi Ye, Yang Yang, Chuqiao Lyu, Shilong Mu, Xueqian Wang, Zhaoqian Xie#, Changsheng Wu#, Xinge Yu#, Wenbo Ding# </i><br>
              <i>Nature Sensors</i><br>  <font color="#FF0000">Selected as the core element for the cover</font><br>
<font color="#FF0000">The first paper of China published in Nature Sensors</font><br>
              <a href="media\paper\nats2026\paper.pdf" target="_blank">PDF</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\nats2026\video.mp4" target="_blank">Video</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://www.nature.com/articles/s44460-025-00006-y" target="_blank">Source</a>
            </p>
          </div>
        </div>

















        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\TRO2024\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>M3Tac: A Multispectral Multimodal Visuotactile  Sensor with Beyond-Human Sensory Capabilities</h3>
            <p>
              <i><b>Shoujie Li</b>, Haixin Yu, Guoping Pan, Huaze Tang, Jiawei Zhang, Linqi Ye#, Xiao-Ping Zhang, Wenbo Ding#</i><br>
              <i>IEEE TRANSACTIONS ON ROBOTICS (T-RO)</i><br>
              <a href="media\paper\TRO2024\paper.pdf" target="_blank">PDF</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\TRO2024\video.mp4" target="_blank">Video</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://ieeexplore.ieee.org/document/10682561" target="_blank">Source</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href=" https://sites.google.com/view/MTac-sensor" target="_blank">Webpage</a>
            </p>
          </div>
        </div>


        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\TRO2022\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>Visual-tactile Fusion for Transparent Object  Grasping in Complex Backgrounds</h3>
            <p>
              <i><b>Shoujie Li*</b>, Haixin Yu*, Wenbo Ding#, Houde Liu#, Linqi Ye, Chongkun Xia, Xueqian Wang, Xiao-Ping  Zhang</i><br>
              <i>IEEE TRANSACTIONS ON ROBOTICS (T-RO)</i> <br> <font color="#FF0000">  2023 Shenzhen Excellent Science and Technology Paper </font> <br>
              <a href="media\paper\TRO2022\paper.pdf" target="_blank">PDF</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\TRO2022\video.mp4" target="_blank">Video</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://ieeexplore.ieee.org/document/10175024/" target="_blank">Source</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href=" https://sites.google.com/view/visual-tactilefusion/" target="_blank">Webpage</a>
            </p>
          </div>
        </div>

        
  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\SoftRobotics2022\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>JamTac: A Tactile Jamming Gripper for Searching  and Grasping in Low-Visibility Environments</h3>
      <p>
        <i><b>Shoujie Li*</b>, Linqi Ye*, Haixin Yu, Xianghui Yin, Chongkun Xia, Wenbo Ding, Xueqian Wang#, and Bin Liang#</i><br>
        <i> Soft Robotics (Soro)

         <br> <font color="#FF0000">  The second prize of China Postgraduate Robot Innovation and Design Competition </font>
        </i><br>
        <a href="media\paper\SoftRobotics2022\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\SoftRobotics2022\video.mp4" target="_blank">Video</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://www.liebertpub.com/doi/abs/10.1089/soro.2022.0134?journalCode=soro" target="_blank">Source</a>
      </p>
    </div>
  </div>
        
        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\TMECH2025\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>VTire: A Bimodal Visuotactile Tire with High-Resolution Sensing Capability</h3>
            <p>
              <i><b>Shoujie Li*</b>, Jianle Xu*, Tong Wu, Yang Yang, Yanbo Chen, Xueqian Wang, Wenbo Ding, Xiao-Ping Zhang</i><br>
              <i>IEEE/ASME Transactions on Mechatronics (T-MECH)</i><br>
              <a href="media\paper\TMECH2025\paper.pdf" target="_blank">PDF</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\TMECH2025\video.mp4" target="_blank">Video</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://arxiv.org/abs/2504.19194" target="_blank">arxiv</a>
            </p>
          </div>
        </div>




        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\ICRA2022\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>TaTa: A Universal Jamming Gripper with High-Quality Tactile Perception and Its Application to Underwater Manipulation</h3>
            <p>
              <i><b>Shoujie Li*</b>, Xianghui Yin*, Chongkun Xia, Linqi Ye, Xueqian Wang#, and Bin Liang</i><br>
              <i>2022 IEEE International Conference on Robotics and Automation (ICRA)</i><br> <font color="#FF0000">  The Outstanding Mechanisms and Design Paper Finalists </font> <br>
              <a href="media\paper\ICRA2022\paper.pdf" target="_blank">PDF</a>
      
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\ICRA2022\video.mp4" target="_blank">Video</a>
      
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://ieeexplore.ieee.org/document/9811806" target="_blank">Source</a>
      
            </p>
          </div>
        </div>


        <div class="list-item publication" data-category="publication">
          <a class="thumbnail"><img src="media\paper\IROS2023\pic.png" alt="" /></a>
          <div class="project-description">
            <h3>Visuotactile Sensor Enabled Pneumatic Device Towards Compliant  Oropharyngeal Swab Sampling</h3>
            <p>
              <i><b>Shoujie Li</b>,Mingshan He, Wenbo Ding#, Linqi Ye, Xueqian Wang, Junbo Tan, Jinqiu Yuan, Xiao-Ping Zhang</i><br>
              <i>2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i><br> 
              
               <font color="#FF0000">  The Best Application Paper Finalists </font> <br>
             <font color="#FF0000">  The second prize of China Postgraduate Robot Innovation and Design Competition </font>
             <br>
              <a href="media\paper\IROS2023\paper.pdf" target="_blank">PDF</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="media\paper\icra20251\video.mp4" target="_blank">Video</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="  https://sites.google.com/view/swab-sampling/" target="_blank">Webpage</a>
              &nbsp;&nbsp;|&nbsp;&nbsp;
              <a href="https://ieeexplore.ieee.org/document/10342266" target="_blank">Source</a>
              </p>
            </div>
          </div>


        




  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\JFR2025\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>SimLiquid: A Simulation-Based Liquid Perception Pipeline for Robot Liquid Manipulation</h3>
      <p>
        <i>Yan Huang*, Jiawei Zhang*, Ran Yu, <b>Shoujie Li#</b>, Wenbo Ding#  (#Corresponding author)</i><br> 
        <i>Journal of Field Robotics  (J-FR)</i> <br> 
         <font color="#FF0000">  Front Cover, Volume 42, Mar, 2025. </font> <br>
        <a href="media\paper\JFR2025\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
       <a href="https://onlinelibrary.wiley.com/doi/10.1002/rob.22548?af=R" target="_blank">Source</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://simliquid.github.io/" target="_blank">Webpage</a>
      </p>
    </div>
  </div>












    <div class="list-item publication" data-category="publication">
    <h2 class="subsection-title publication">Other works</h2>
  </div>





  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\JSTSP\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>When Vision Meets Touch: A Contemporary Review for Visuotactile Sensors from the Signal Processing Perspective</h3>
      <p>
        <i><b>Shoujie Li</b>, Zihan Wang, Changsheng Wu, Xiang Li, Shan Luo, Bin Fang, Fuchun Sun, Xiao-Ping Zhang, Wenbo Ding#</i><br>
        <i>IEEE Journal of Selected Topics in Signal Processing (JSTSP)</i><br>
        <a href="media\paper\JSTSP\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://ieeexplore.ieee.org/document/10563188" target="_blank">Source</a>
      </p>
    </div>
  </div>







        <div class="list-item publication" data-category="publication">
      <a class="thumbnail"><img src="media\paper\icra20251\pic.png" alt="" /></a>
      <div class="project-description">
        <h3>Chemistry3D: Robotic Interaction Toolkit for Chemistry Experiments</h3>
        <p>
          <i><b>Shoujie Li*</b>, Yan Huang*, Changqing Guo*, Tong Wu, Jiawei Zhang, Linrui Zhang, Wenbo Ding#</i><br>
          <i>2025 IEEE International Conference on Robotics and Automation (ICRA) </i><br>
          <a href="media\paper\icra20251\paper.pdf" target="_blank">PDF</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="media\paper\icra20251\video.mp4" target="_blank">Video</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://github.com/huangyan28/Chemistry3D" target="_blank">Code</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://www.omni-chemistry.com/#/" target="_blank">Webpage</a>
        </p>
      </div>
    </div>




    <div class="list-item publication" data-category="publication">
      <a class="thumbnail"><img src="media\paper\RAL2026-1\pic.png" alt="" /></a>
      <div class="project-description">
        <h3>CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space</h3>
        <p>
          <i>Tong Wu*, <b>Shoujie Li*</b>, Junhao Gong, Changqing Guo, Xingting Li, Shilong Mu, Wenbo Ding</i><br>
          <i>IEEE ROBOTICS AND AUTOMATION LETTERS (RAL)</i><br>
          <a href="media\paper\RAL2026-1\paper.pdf" target="_blank">PDF</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="media\paper\RAL2026-1\video.mp4" target="_blank">Video</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href=" https://cross-embodiment-interface.github.io/" target="_blank">Webpage</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://www.arxiv.org/abs/2601.09163" target="_blank">Source</a>
        </p>
      </div>
    </div>
    






    <div class="list-item publication" data-category="publication">
      <a class="thumbnail"><img src="media\paper\RAL2022\pic.png" alt="" /></a>
      <div class="project-description">
        <h3>TGF-Net: Sim2Real Transparent Object 6D Pose  Estimation Based on Geometric Fusion</h3>
        <p>
          <i>Haixin Yu*, <b>Shoujie Li*</b>, Houde Liu, Chongkun Xia, Wenbo Ding, and Bin Liang</i><br>
          <i>IEEE ROBOTICS AND AUTOMATION LETTERS (RAL)</i><br>
          <a href="media\paper\RAL2022\paper.pdf" target="_blank">PDF</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="media\paper\RAL2022\video.mp4" target="_blank">Video</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href=" https://sites.google.com/view/tgfnet" target="_blank">Webpage</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://ieeexplore.ieee.org/document/10103597" target="_blank">Source</a>
        </p>
      </div>
    </div>
    


    <div class="list-item publication" data-category="publication">
      <a class="thumbnail"><img src="media\paper\Nanoenergy2023\pic.png" alt="" /></a>
      <div class="project-description">
        <h3>A platypus-inspired electro-mechanosensory finger for remote control and tactile sensing</h3>
        <p>
          <i>  Shilong Mu*,  <b>Shoujie Li*</b>,  Hongfa Zhao*, Zihan Wang, Xiao Xiao, Xiao Xiao, Zenan Lin, Ziwu Song, Huaze Tang, Qinghao Xu, Dongkai Wang, Wang Wei Lee#, Changsheng Wu#, Wenbo Ding#</i><br>
          <i>Nano Energy</i><br>
          <a href="media\paper\Nanoenergy2023\paper.pdf" target="_blank">PDF</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://www.sciencedirect.com/science/article/abs/pii/S2211285523006274" target="_blank">Source</a>
        </p>
      </div>
    </div>


  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\SMC2021\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>Design of a Tactile Sensing Robotic Gripper and Its Grasping Method</h3>
      <p>
        <i><b>Shoujie Li,</b>, Linqi Ye, Chongkun Xia, Xueqian Wang#, and Bin Liang</i><br>
        <i>2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)</i><br>
        <a href="media\paper\SMC2021\paper.pdf" target="_blank">PDF</a>  
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://ieeexplore.ieee.org/document/9658599" target="_blank">Source</a>
      </p>
    </div>
  </div>



  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\CAAI\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>Growing from Exploration: A Self-Exploring Framework for Robots Based on Foundation Models</h3>
      <p>
        <i><b>Shoujie Li*</b>, Ran Yu*, Tong Wu*, Junwen Zhong, Xiao-Ping Zhang, and Wenbo Ding#</i><br>
        <i>CAAI Artificial Intelligence Research</i><br>
        <a href="media\paper\CAAI\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://arxiv.org/pdf/2401.13462" target="_blank">Arxiv</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://sites.google.com/view/gexp" target="_blank">Webpage</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://www.sciopen.com/article/10.26599/AIR.2024.9150037" target="_blank">Source</a>
      </p>
    </div>
  </div>

    <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\Device2025\pic.jpg" alt="" /></a>
    <div class="project-description">
      <h3>Origami self-powered near-sensor computing system using 2D materials for deformation monitoring</h3>
      <p>
        <i>Rongjie Zhang, Qinghao Xu, Yujie Sun,Zenan Lin,Keyou Wu, Ziwu Song, Zhentan Quan, Huaze Tang, Zihan Wang,Hongfa Zhao, <b>Shoujie Li</b>, Wenbo Ding,Hui-Ming Cheng, Bilu Liu</i><br>
        <i> Device

         <br> <font color="#FF0000"> Front Cover </font>
        </i><br>
        <a href="media\paper\Device2025\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S2666998625002467" target="_blank">Source</a>
      </p>
    </div>
  </div>


    <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\Nips2025\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>Universal Visuo-Tactile Video Understanding for Embodied Interaction</h3>
      <p>
        <i>Yifan Xie, Mingyang Li, <b>Shoujie Li</b>, Xingting Li, Guangyu Chen, Fei Ma, Fei Richard Yu, Wenbo Ding</i><br>
        <i>The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</i><br>
        <a href="media\paper\Nips2025\paper.pdf" target="_blank">PDF</a>  
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://arxiv.org/abs/2505.22566" target="_blank">Source</a>
      </p>
    </div>
  </div>




    <div class="list-item publication" data-category="publication">
      <a class="thumbnail"><img src="media\paper\icra20253\pic.png" alt="" /></a>
      <div class="project-description">
        <h3>Depth Restoration of Hand-Held Transparent Objects for Human-to-Robot Handover</h3>
        <p>
          <i> Ran Yu*, Haixin Yu*, <b>Shoujie Li*</b>, Yan Huang, Ziwu Song, Wenbo Ding#</i><br>
          <i>2025 IEEE International Conference on Robotics and Automation (ICRA)</i><br>
          <a href="media\paper\icra20253\paper.pdf" target="_blank">PDF</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="media\paper\icra20253\video.mp4" target="_blank">Video</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://github.com/MarcYu0303/Trans-HADR/tree/main" target="_blank">Code</a>
          &nbsp;&nbsp;|&nbsp;&nbsp;
          <a href="https://marcyu0303.github.io/HADR.github.io/" target="_blank">Webpage</a>
        </p>
      </div>
    </div>

    <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\IROS2025-2\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>MuxHand: A Cable-driven Dexterous Robotic Hand Using Time-division Multiplexing Motors</h3>
      <p>
        <i> Jianle Xu*, <b>Shoujie Li*</b>, Hong Luo, Houde Liu#, Xueqian Wang, Wenbo Ding, Chongkun Xia</i><br>
        <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i><br>
        <a href="media\paper\IROS2025-2\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\IROS2025-2\video.mp4" target="_blank">Video</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://xujianle.github.io/MuxHand.github.io/" target="_blank">Webpage</a>
      </p>
    </div>
  </div>


    <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\IROS2025-1\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception</h3>
      <p>
       <i>Junhao Gong*, Kit-Wa Sou*, <b>Shoujie Li#</b>, Changqing Guo, Yan Huang, Chuqiao Lyu, Ziwu Song, Wenbo Ding#</i><br>
        <i>2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</i><br>
        <a href="media\paper\IROS2025-1\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\IROS2025-1\video.mp4" target="_blank">Video</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://ultratac.junhaogong.top/" target="_blank">Webpage</a>
      </p>
    </div>
  </div>


  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\icra20255\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>Efficient Collision Detection Framework for Enhancing Collision-Free Robot Motion</h3>
      <p>
        <i>  Xiankun Zhu, Yucheng Xin, <b>Shoujie Li</b>, Houde Liu#, Chongkun Xia, Bin Liang</i><br>
        <i>2025 IEEE International Conference on Robotics and Automation (ICRA)</i><br>
        <a href="media\paper\icra20255\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\icra20255\video.mp4" target="_blank">Video</a>
      </p>
    </div>
  </div>


  <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\icra20256\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>D3-ARM: High-Dynamic, Dexterous and Fully Decoupled Cable-driven Robotic Arm</h3>
      <p>
        <i> Hong Luo, Jianle Xu, <b>Shoujie Li</b>, Huayue Liang, Yanbo Chen, Chongkun Xia, Xueqian Wang</i><br>
        <i>2025 IEEE International Conference on Robotics and Automation (ICRA)</i><br>
        <a href="media\paper\icra20256\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\icra20256\video.mp4" target="_blank">Video</a>
      </p>
    </div>
  </div>

    <div class="list-item publication" data-category="publication">
      <h2 class="subsection-title publication">Works in review</h2>
    </div>
    
    <div class="list-item publication" data-category="publication">
    <a class="thumbnail"><img src="media\paper\icra20254\pic.png" alt="" /></a>
    <div class="project-description">
      <h3>MoDex: Planning High-Dimensional Dexterous Control via Learning Neural Hand Models</h3>
      <p>
        <i>  Tong Wu*, <b>Shoujie Li*</b>,Chuqiao Lyu, Kit-Wa Sou, Wang-Sing Chan, Wenbo Ding#</i><br>
        <i>Under review</i><br>
        <a href="media\paper\icra20254\paper.pdf" target="_blank">PDF</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="media\paper\icra20254\video.mp4" target="_blank">Video</a>
        &nbsp;&nbsp;|&nbsp;&nbsp;
        <a href="https://tongwu19.github.io/MoDex/" target="_blank">Webpage</a>
      </p>
    </div>
  </div>

        <!-- honors -->
        <div id="main-highlights">

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2025</p>Award,  Future Leaders Scholarship in Tsinghua University (Top 2%), Tsinghua University.   
          </div>


            <div class="list-item highlight" data-category="highlight">
            <p class="date">2025</p>Award, Outstanding Doctoral Dissertations of Tsinghua University (10%).   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2025</p>Award, Outstanding Doctoral Graduate of Tsinghua University (4%).   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2024</p>Award, The Autonomous Robotic Technology Seminar (ARTS) Scholarship, Shenzhen 2024.   
          </div>
          
          <div class="list-item highlight" data-category="highlight">
            <p class="date">2024</p>Award, The Champion of  Picking in Clutter in International Dexterity Challenge, Zhuhai 2024.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2024</p>Award, The second prize of China Postgraduate Robot Innovation and Design Competition, Liaoning 2024.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2024</p>Award,  Winner of Robotic Grasping of  Manipulation Competition - Picking in Clutter, ICRA 2024.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award, The second prize of China Postgraduate Robot Innovation and Design Competition, Hangzhou 2023.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award,  Future Leaders Scholarship in Tsinghua University (Top 2%), Tsinghua University.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award,  PhD National Scholarship in Tsinghua University (Top 2%), Tsinghua University.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award,  Future Scholars Scholarship in Tsinghua University (Top 2%), Tsinghua University.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award,   Excellent Science & Technology Academic Paper, ShenZhen.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2023</p>Award,  Best Application Paper Finalists, IROS 2023.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2022</p>Award,  Outstanding Mechanisms and Design Paper Award Finalist, ICRA 2023.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2022</p>Award, The second prize of China Postgraduate Robot Innovation and Design Competition, Changsha 2022.   
          </div>

          <div class="list-item highlight" data-category="highlight">
            <p class="date">2022</p>Award, The second prize of China Postgraduate Artificial Intelligence Innovation  Competition, Shenzhen 2022.   
          </div>
        </div>

        <!-- Talks -->
        <div class="list-item talk" data-category="talk">
          <p class="date">2026</p> 1 paper is accepted by IEEE Robotics and Automation Letters (RAL)</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> Honored to present at <a href="https://mp.weixin.qq.com/s/RH81IVXiLUiv3Tvmr85QHw"> MLNLP2025</a></a>!
        </div>
          <div class="list-item talk" data-category="talk">
          <p class="date">2025</p>1 paper is accepted by Nature Sensors</a>!!!!
        </div>
         <div class="list-item talk" data-category="talk">
          <p class="date">2025</p>The paper accepted by Journal of Field Robotics (J-FR) is selected as Front Cover</a>!
        </div>
          <div class="list-item talk" data-category="talk">
          <p class="date">2025</p>I award Outstanding Doctoral Graduate of Tsinghua University(4%)</a>!
        </div>
            <div class="list-item talk" data-category="talk">
          <p class="date">2025</p>I award Outstanding Doctoral Dissertation of Tsinghua University(10%)</a>!
        </div>
            <div class="list-item talk" data-category="talk">
          <p class="date">2025</p>I Graduate form Tsinghua university</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> 6 papers have been accepted by IROS 2025</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> 1 paper has been accepted by IEEE Transactions on Mechatronics (T-MECH)</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> Honored to present at <a href="https://mp.weixin.qq.com/s/whmOOR9up_JzomThUGgwcw"> Peking University Shenzhen Graduate School</a></a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> 1 paper has been accepted by Journal of Field Robotics (J-FR)</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> Honored to present at the Institute of Superlubricity Technology, thanks to <a href="https://scholar.google.com/citations?user=vZBn5ywAAAAJ&hl=en"> Academician Zheng Quanshui</a></a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> 1 paper is accepted by IEEE Robotics and Automation Letters (RAL)</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2025</p> 5 papers are accepted by ICRA 2025</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2024</p> I get the Autonomous Robotic Technology Seminar (ARTS) Scholarship</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2024</p> We get the champion of Picking in Clutter in International Dexterity Challenge and win 8w RMB</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2024</p> We get the second prize of China Postgraduate Robot Innovation and Design Competition</a>!
        </div>
        <div class="list-item talk" data-category="talk">
          <p class="date">2024</p> 1 paper has been accepted by IEEE Transactions on Robotics (T-RO) </a>!
        </div>

        <!-- Services -->
        <!-- <div class="list-item misc" data-category="misc">
          <p class="date">2023</p>Reviewer, RAL
        </div> -->

        <!-- <div class="list-item misc" data-category="misc">
          <p class="date">2019+</p>Reviewer, ICRA, IROS, RAL
        </div> -->

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>Reviewer,T-RO, TASE, ICRA, IROS, RAL
        </div>

        <div class="list-item misc" data-category="misc">
          <p class="date"></p>Student Member, IEEE
   
        </div>


        <div class="list-item misc" data-category="misc">
          <p class="date"></p>Student Member, RAS
   
        </div>

      </div>
      

      <div id="footer">  
      Pageviews: <a href="https://www.easycounter.com/"><img src="https://www.easycounter.com/counter.php?dengyh16" border="0" alt="Free Web Counter"></a>
      <br>
      Feel free to use this website's <a href="https://github.com/dengyh16code/dengyh16code.github.io">source code</a>. Inspired by <a href="https://andyzeng.github.io/">Andy's website</a>.
      </div>

    </div>




<script>
  // 初始化 Isotope
  var $grid = $('.grid').isotope({
    itemSelector: '.list-item',
    layoutMode: 'fitRows',
    transitionDuration: 0,
    stagger: 10,
    initLayout: false,
    getSortData: {
      name: '.name',
      symbol: '.symbol',
      number: '.number parseInt',
      category: '[data-category]',
      weight: function( itemElem ) {
        var weight = $( itemElem ).find('.weight').text();
        return parseFloat( weight.replace( /[\(\)]/g, '') );
      }
    }
  });

  // 监听所有图片加载完成后刷新布局
  $(window).on('load', function() {
    $grid.isotope('layout');
  });

  // 你的后续逻辑...
</script>









    <script>

      // Isotope grid.
      var $grid = $('.grid').isotope({
        itemSelector: '.list-item',
        layoutMode: 'fitRows',
        transitionDuration: 0,
        stagger: 10,
        initLayout: false,
        getSortData: {
          name: '.name',
          symbol: '.symbol',
          number: '.number parseInt',
          category: '[data-category]',
          weight: function( itemElem ) {
            var weight = $( itemElem ).find('.weight').text();
            return parseFloat( weight.replace( /[\(\)]/g, '') );
          }
        }
      });

      // Bind filter button click.
      $('#filters').on( 'click', 'button', function() {
        var filterValue = $( this ).attr('data-filter');
        localStorage.setItem('filterValue', filterValue);
        $grid.isotope({ filter: filterValue });
      });

      // Change is-checked class on buttons.
      $('.button-group').each( function( i, buttonGroup ) {
        var $buttonGroup = $( buttonGroup );
        $buttonGroup.on( 'click', 'button', function() {
          $buttonGroup.find('.is-checked').removeClass('is-checked');
          $( this ).addClass('is-checked');
        });
      });

      function update_isotope() {
        // Retrieve cached button click.
        var defaultFilterValue = localStorage.getItem('filterValue');
        if (defaultFilterValue == null) {
          defaultFilterValue = ".publication"
        }
        $grid.isotope({ filter: defaultFilterValue });
        var buttons = document.getElementsByClassName("button");
        for (var currButton of buttons) {
          if (currButton.getAttribute('data-filter') == defaultFilterValue) {
            currButton.classList.add('is-checked');
          } else {
            currButton.classList.remove('is-checked');
          }
        }
      }

      document.getElementById("toggleLink").addEventListener("click", function(event) {
      event.preventDefault(); // Prevent the default anchor link behavior
      var audioPlayer = document.getElementById("myAudioPlayer");
      audioPlayer.style.display = audioPlayer.style.display === "none" ? "block" : "none";
      });



      update_isotope();

    </script>
  </body>
</html>
